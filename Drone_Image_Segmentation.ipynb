{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drone Image Segmentation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "import datetime\n",
    "import numpy as np\n",
    "import keras\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "#from keras_fcn import FCN\n",
    "#from voc_generator import PascalVocGenerator, ImageSetLoader\n",
    "from keras.callbacks import (\n",
    "    ReduceLROnPlateau,\n",
    "    CSVLogger,\n",
    "    EarlyStopping,\n",
    "    ModelCheckpoint,\n",
    "    TerminateOnNaN)\n",
    "#from keras_fcn.callbacks import CheckNumericsOps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "global _SESSION\n",
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "_SESSION = tf.Session(config=config)\n",
    "K.set_session(_SESSION)\n",
    "\n",
    "with open(\"init_args.yml\", 'r') as stream:\n",
    "    try:\n",
    "        init_args = yaml.load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointer = ModelCheckpoint(\n",
    "    filepath=\"/tmp/fcn_vgg16_weights.h5\",\n",
    "    verbose=1,\n",
    "    save_best_only=True)\n",
    "lr_reducer = ReduceLROnPlateau(monitor='val_loss',\n",
    "                               factor=np.sqrt(0.1),\n",
    "                               cooldown=0,\n",
    "                               patience=10, min_lr=1e-12)\n",
    "early_stopper = EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0.001,\n",
    "                              patience=30)\n",
    "nan_terminator = TerminateOnNaN()\n",
    "csv_logger = CSVLogger('output/tmp_fcn_vgg16.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datagen = PascalVocGenerator(image_shape=[224, 224, 3],\n",
    "                                    image_resample=True,\n",
    "                                    pixelwise_center=True,\n",
    "                                    pixel_mean=[115.85100, 110.50989, 102.16182],\n",
    "                                    pixelwise_std_normalization=True,\n",
    "                                    pixel_std=[70.30930, 69.41244, 72.60676])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_loader = ImageSetLoader(**init_args['image_set_loader']['train'])\n",
    "val_loader = ImageSetLoader(**init_args['image_set_loader']['val'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model\n",
    "fcn_vgg16 = FCN(input_shape=(224, 224, 3), classes=21, weight_decay=3e-3,\n",
    "                weights='imagenet', trainable_encoder=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# optimizer\n",
    "optimizer = keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_vgg16.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_vgg16.fit_generator(\n",
    "    datagen.flow_from_imageset(\n",
    "        class_mode='categorical',\n",
    "        classes=21,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        image_set_loader=train_loader),\n",
    "    steps_per_epoch=1112,\n",
    "    epochs=100,\n",
    "    validation_data=datagen.flow_from_imageset(\n",
    "        class_mode='categorical',\n",
    "        classes=21,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        image_set_loader=val_loader),\n",
    "    validation_steps=1111,\n",
    "    verbose=1,\n",
    "    callbacks=[lr_reducer, early_stopper, csv_logger, checkpointer, nan_terminator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fcn_vgg16.save('output/fcn_vgg16.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Fully Convolutional Neural Networks.\"\"\"\n",
    "from __future__ import (\n",
    "    absolute_import,\n",
    "    unicode_literals\n",
    ")\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Flatten, Activation, Reshape\n",
    "\n",
    "\n",
    "from keras_fcn.encoders import VGG16, VGG19\n",
    "from keras_fcn.decoders import VGGDecoder, VGGUpsampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model detailed\n",
    "def FCN_VGG16(input_shape, classes, weight_decay=0.,\n",
    "              trainable_encoder=True, weights=None):\n",
    "    \"\"\"Fully Convolutional Networks for semantic segmentation with VGG16.\n",
    "    # Arguments\n",
    "        input_shape: input image shape\n",
    "        classes: number of classes\n",
    "        trainable_encoder: Bool whether the weights of encoder are trainable\n",
    "        weights: pre-trained weights to load (None for training from scratch)\n",
    "    # Returns\n",
    "        A Keras model instance\n",
    "    \"\"\"\n",
    "    # input\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # Get the feature pyramid [drop7, pool4, pool3] from the VGG16 encoder\n",
    "    pyramid_layers = 3\n",
    "    encoder = VGG16(inputs, weight_decay=weight_decay,\n",
    "                    weights=weights, trainable=trainable_encoder)\n",
    "    feat_pyramid = encoder.outputs[:pyramid_layers]\n",
    "\n",
    "    # Append image to the end of feature pyramid\n",
    "    feat_pyramid.append(inputs)\n",
    "\n",
    "    # Decode feature pyramid\n",
    "    outputs = VGGUpsampler(feat_pyramid, scales=[1, 1e-2, 1e-4], classes=classes, weight_decay=weight_decay)\n",
    "\n",
    "    # Activation TODO{jihong} work only for channels_last\n",
    "    scores = Activation('softmax')(outputs)\n",
    "\n",
    "    # return model\n",
    "    return Model(inputs=inputs, outputs=scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagation(...):\n",
    "    # from X to cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mean_categorical_crossentropy(y_true, y_pred):\n",
    "    if K.image_data_format() == 'channels_last':\n",
    "        loss = K.mean(keras.losses.categorical_crossentropy(y_true, y_pred), axis=[1, 2])\n",
    "    elif K.image_data_format() == 'channels_first':\n",
    "        loss = K.mean(keras.losses.categorical_crossentropy(y_true, y_pred), axis=[2, 3])\n",
    "    return loss\n",
    "\n",
    "def flatten_categorical_crossentropy(classes):\n",
    "    def f(y_true, y_pred):\n",
    "        y_true = K.reshape(y_true, (-1, classes))\n",
    "        y_pred = K.reshape(y_pred, (-1, classes))\n",
    "        return keras.losses.categorical_crossentropy(y_true, y_pred)\n",
    "    return f"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
